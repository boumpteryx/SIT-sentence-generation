# SIT-sentence-generation
<a target="_blank" href="https://colab.research.google.com/github/boumpteryx/SIT-sentence-generation/blob/main/Perplexity.ipynb">
  <img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/>
</a>

The goal of this project is to evaluate the perplexity of sentences generated by https://contenttool.io/random-sentence-generator/result?fileName=c2VudGVuY2Vzcw== VS those used already in research.

SIT sentences are meant to be correct but not very predictable. This way, a new reader cannot predict the next word before actually reading it and prepare himself for a reading-out-loud task for example. This allows to reduce confounding factors due to litteracy levels. The metric for low predictability is called perplexity and can be evaluated thanks to a large language model, such as BERT. 
